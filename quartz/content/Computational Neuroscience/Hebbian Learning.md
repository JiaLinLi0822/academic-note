https://medium.com/@reutdayan1/hebbian-learning-biologically-plausible-alternative-to-backpropagation-6ee0a24deb00

The problem of learning to learn

- The brains through synapitic plasticity
- synapses change automaticlally as a function of neural firing
- Main form: Hebbian plasticity
- Hebbian learning is unsupervised but produces goal-directed learning
    - Can we replace evolution with gradient descent



$$
in model6, p(c1, c2, rt1, rt2) = p(c1, rt1) p(c2, rt2), so it seems ok to me? though I agree with you for models 1-5

\sum_{c2} \int p(c1, rt1) p(c2, rt2) drt2 = p(c1, rt1) \sum_{c2} \int p(c2, rt2) drt2 = p(c1, rt1)
$$
